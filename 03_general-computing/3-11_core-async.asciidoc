[[sec_general_core_async]]
=== Decoupling Consumers and Producers with core.async
[role="byline"]
by Daemian Mack

==== Problem

You want to decouple your program's consumers and producers by
introducing explicit queues between them.(((consumer/producer decoupling)))(((core.async)))(((asynchronous coordination)))(((decoupling consumers/producers)))((("server-sent events (SSE)")))

For example, if you are building a web dashboard that fetches Twitter
messages, this application must both persist these events to a database and
publish them via server-sent events (SSE) to a browser.

==== Solution

Introducing explicit queues between components allows them to
communicate asynchronously, making them simpler to manage independently
and freeing up computational resources.

Use the https://github.com/clojure/core.async[+core.async+]
library to introduce and coordinate asynchronous channels.

To follow along with this recipe, start a REPL using +lein-try+:

[source,shell-session]
----
$ lein try org.clojure/core.async
----

Consider the following passage illustrating a synchronous approach:

[source,clojure]
----
(defn database-consumer
  "Accept messages and persist them to a database."
  [msg]
  (println (format "database-consumer received message %s" msg)))

(defn sse-consumer
  "Accept messages and pass them to web browsers via SSE."
  [msg]
  (println (format "sse-consumer received message %s" msg)))

(defn messages
  "Fetch messages from Twitter."
  []
  (range 4))

(defn message-producer
  "Produce messages and deliver them to consumers."
  [& consumers]
  (doseq [msg (messages)
          consumer consumers]
    (consumer msg)))

(message-producer database-consumer sse-consumer)
;; *out*
;; database-consumer received message 0
;; sse-consumer received message 0
;; database-consumer received message 1
;; sse-consumer received message 1
;; database-consumer received message 2
;; sse-consumer received message 2
;; database-consumer received message 3
;; sse-consumer received message 3
----

Each message received is passed directly to each consumer of
+message-producer+. As implemented, this approach is rather brittle;
any slow consumer could cause the entire pipeline to grind to a halt.

To make processing asynchronous, introduce explicit queues with
+clojure.core.async/chan+. Perform work asynchronously by wrapping
it in one of ++core.async++'s +clojure.core.async/go+ forms:

[source,clojure]
----
(require '[clojure.core.async :refer [chan sliding-buffer go
                                      go-loop timeout >! <!]])

(defn database-consumer
  "Accept messages and persist them to a database."
  []
  (let [in (chan (sliding-buffer 64))]
    (go-loop [data (<! in)]
             (when data
               (println (format "database-consumer received data %s" data))
               (recur (<! in))))
    in))

(defn sse-consumer
  "Accept messages and pass them to web browsers via SSE."
  []
  (let [in (chan (sliding-buffer 64))]
    (go-loop [data (<! in)]
             (when data
               (println (format "sse-consumer received data %s" data))
               (recur (<! in))))
    in))

(defn messages
  "Fetch messages from Twitter."
  []
  (range 4))

(defn producer
  "Produce messages and deliver them to consumers."
  [& channels]
  (go
   (doseq [msg (messages)
           out  channels]
     (<! (timeout 100))
     (>! out msg))))

(producer (database-consumer) (sse-consumer))
;; *out*
;; database-consumer received data 0
;; sse-consumer received data 0
;; database-consumer received data 1
;; sse-consumer received data 1
;; database-consumer received data 2
;; sse-consumer received data 2
;; database-consumer received data 3
;; sse-consumer received data 3
----

==== Discussion

[quote, Rich Hickey, Clojure core.async Channels]
____
There comes a time in all good programs when components or subsystems
must stop communicating directly with one another.
____

This code is larger than the original implementation. What has this
afforded us?

The original approach was rigid. It offered no control over consumer
latency and was therefore extremely vulnerable to lag. By buffering
communication over channels and doing work asynchronously, we've
created service boundaries around producers and consumers, allowing
them to operate as independently as possible.(((consumer latency)))

Let's examine one of the new consumers in depth to understand how it
has changed. 

Instead of receiving messages via function invocation,
consumers now draw messages from a buffered channel. Where a consumer
(e.g., +database-consumer+) used to consume a single message at a time,
it now uses a +go-loop+ to continuously consume messages from its
producer.

In traditional callback-oriented code, accomplishing something like
this would require splitting logic out across numerous functions,
introducing "callback hell." One of the benefits of +core.async+ is
that it lets you write code inline, in a more straightforward style:

[source,clojure]
----
(defn database-consumer
  "Accept messages and persist them to a database."
  []
  (let [in (chan (sliding-buffer 64))] ; <1>
    (go-loop [data (<! in)]            ; <2>
             (when data                ; <3>
               (println (format "database-consumer received data %s" data))
               (recur (<! in))))       ; <4>
    in))
----

<1> Here the channel is given a buffer of size 64. The
    +sliding-buffer+ variant dictates that if this channel
    accumulates more than 64 unread values, older values will start
    "falling off" the end, trading off historical completeness in
    favor of recency. Using +dropping-buffer+ instead would optimize
    in the opposite direction.
<2> +go-loop+ is the +core.async+ equivalent to looping via something
    like +while true+. This +go-loop+ reads its initial value by
    "taking" (+<!+) from the input channel (+in+).
<3> Because channels return +nil+ when closed, as long as we can read
    +data+ from them, we know we have work to do.
<4> To +recur+ the +go-loop+ to the beginning, take the next value
    from the channel and invoke +recur+ with it.

Because the +go-loop+ block is asynchronous, the take call (+<!+)
parks until a value is placed on the channel. The remainder of the
+go-loop+ block--here, the +println+ call--is pending. Since the
channel is returned as the +database-consumer+ function's value, other
parts of the system--namely, the producer--are free to write to
the channel while the take waits. The first value written to the
channel will satisfy that read call, allowing the rest of the
+go-loop+ block to continue.

This consumer is now asynchronous, reading values until the channel
closes. Since the channel is buffered, we now have some measure of
control over the system's resiliency. For example, buffers allow a
consumer to lag behind a producer by a specified amount.

Fewer changes are required to make +producer+ asynchronous:

[source,clojure]
----
(defn producer
  [& channels]
  (go
   (doseq [msg (messages)
           out  channels] ; <1>
     (<! (timeout 100))   ; <2>
     (>! out item))))     ; <3>
----

<1> For each message and channel...
<2> Take from a +timeout+ channel to simulate a short pause for effect...
<3> And put a message onto the channel with +>!+.

Although the operations are asynchronous, they still occur serially.
Using unbuffered consumer channels would mean that if one of the consumers
took from the channel too slowly, the pipeline would stall; the
producer would not be able to put further values onto the channels.

==== See Also

* +core.async+ has more advanced facilities for layout and coordination
  of channels. For more details, see the
  http://bit.ly/core-async-doc[+core.async+ overview].
* <<sec_concurrent_zmq>> to see how to use +core.async+ to communicate
  over ZeroMQ.

