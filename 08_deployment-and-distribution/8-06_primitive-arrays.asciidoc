[[sec_deployment_primitive_arrays]]
=== Fast Math with Primitive Java Arrays
[role="byline"]
by Jason Wolfe

==== Problem

You need to perform fast numerical operations over significant amounts
of data.((("performance/production", "fast math")))(((numeric operations, increasing speed of)))(((primitive arrays)))(((Java, primitive arrays)))(((arrays, primitive arrays)))

==== Solution

Primitive Java arrays are the canonical way to store large collections
of numbers compactly and do math over them quickly (often 100 times faster
than Clojure sequences). The https://github.com/Prismatic/hiphip[+hiphip+ (array)] library is a
quick and easy way to manipulate primitive arrays of +double+, +long+, +float+, or
+int+ members.

Before starting, add `[prismatic/hiphip "0.1.0"]` to your project's
dependencies or start a REPL using +lein-try+:

[source,text]
----
$ lein try prismatic/hiphip
----

Use one of ++hiphip++'s +amap+ macros to perform fast math on typed
arrays. +amap+ uses a parallel binding syntax similar to +doseq+:

[source,clojure]
----
(require 'hiphip.double)

(defn map-sqrt [xs]
  (hiphip.double/amap [x xs] (Math/sqrt x)))

(seq (map-sqrt (double-array (range 5)))) 
;; -> (0.0 1.0 1.4142135623730951 1.7320508075688772 2.0)

(defn pointwise-product
  "Produce a new double array with the product of corresponding elements of
  xs and ys"
  [xs ys]
  (hiphip.double/amap [x xs y ys] (* x y)))
(seq (pointwise-product (double-array [1.0 2.0 3.0])
                        (double-array [2.0 3.0 4.0])))
;; -> (2.0 6.0 12.0)
----

To modify an array in place, use one of ++hiphip++'s +afill!+ macros:

[source,clojure]
----
(defn add-in-place!
  "Modify xs, incrementing each element by the corresponding element of ys"
  [xs ys]
  (hiphip.double/afill! [x xs y ys] (+ x y)))

(let [xs (double-array [1.0 2.0 3.0])]
  (add-in-place! xs (double-array [0.0 1.0 2.0]))
  (seq xs))
;; -> (1.0 3.0 5.0)
----

For faster +reduce+-like operations, use one of ++hiphip++'s +areduce+ and
+asum+ macros:

[source,clojure]
----
(defn dot-product [ws xs]
  (hiphip.double/asum [x xs w ws] (* x w)))

(dot-product (double-array [1.0 2.0 3.0])
             (double-array [2.0 3.0 4.0]))
;; -> 20.0
----

[WARNING]
====
We'd love to throw in a quick +time+ benchmark to demonstrate the
gains, but the JVM is a fickle beast when it comes to optimizations.
We suggest using https://github.com/hugoduncan/criterium[Criterium]
when benchmarking to avoid common pitfalls.

To see Criterium benchmarks of +hiphip+, see
http://bit.ly/hiphip-bench[w01fe's _bench.clj_ gist].
====

==== Discussion

Most of the time, Clojure's sequence abstraction is all you need to((("sequence abstraction", "vs. primitive arrays")))
get the job done. The preceding +dot-product+ can be written succinctly in
ordinary Clojure, and this is generally what you should try first:

[source,clojure]
----
(defn dot-product [ws xs]
  (reduce + (map * ws xs)))
----

Once you identify a bottleneck in your mathematical operations,
however, primitive arrays may be the only way to go. The preceding
+dot-product+ implementation can be made more than 100 times faster by
using +asum+, primarily because +map+ produces sequences of
'boxed' Java +Double+ objects. In addition to the cost of constructing
an intermediate sequence, all arithmetic operations on boxed numbers
are significantly slower than on their primitive counterparts.

++hiphip++'s +amap+, +afill!+, +areduce+, and +asum+ macros (among others)
are available for +int+, +long+, +float+, and +double+ types. If you
wanted to use +reduce+ over an array of floats, for example, you would
use +hiphip.float/areduce+. These macros define the appropriate
type hints and optimizations per type.

Clojure also comes with
http://clojure.org/java_interop#Java%20Interop-Arrays[built-in
functions] for operating on arrays, although greater care must be
taken to ensure maximal performance (via appropriate type hints and
use of `*unchecked-math*`):

[source,clojure]
----
(set! *unchecked-math* true)
(defn map-inc [^doubles xs]
  (amap xs i ret (aset ret i (inc (aget xs i)))))
----

Working with primitive arrays in Clojure isn't for the faint of heart:
if you don't get _everything_ right, you can easily end up with code
that's both much uglier and no faster (or even slower) than the
straightforward sequence version. The biggest issue to watch out for
is reflection, which can easily bring you from 100 times faster to 10 times
slower with one small typo or missing type hint.

If you're up to the challenge, you should keep these tips in mind:

* Use `*warn-on-reflection*` religiously, but be aware that it won't
  warn you about many of the ways your code can be slow.
* A solid profiler, or at least a comprehensive benchmark suite, is a
  must; otherwise you won't know which function is using 99% of your
  runtime.
* Especially if you're not using +hiphip+, experiment with
  `*unchecked-math*`; it almost always makes your code faster, if
  you're willing to give up the safety of overflow checks.
* If you want your array code to go
  http://bit.ly/lein-tiered-compilation[fast
  under Leiningen], you probably want to add the following to your
  _project.clj_: +:jvm-opts ^:replace []+.


==== See Also

* +hiphip+ comes with a
  http://bit.ly/hiphip-tests[comprehensive
  suite of benchmarks] of its and Clojure's array operations for the
  main primitive types, including performance comparisons with
  handcoded Java alternatives.
* https://github.com/ztellman/vertigo[Vertigo] goes beyond simple
  arrays of primitives to full C-style structs, which may be a good
  choice if you need to manipulate structured data (i.e., not just
  sequences of ++double++s) with maximal performance.
* <<sec_primitives_math_type_hinting>>, to learn more about
  type hinting and unchecked math.
* <<sec_profiling_timbre>>, to learn about using Timbre to output
  profiling statistics from your code.
